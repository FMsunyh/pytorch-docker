{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Task\n",
                "Our task is simple, recognize handwritten digits. We will use MNIST dataset for this tutorial.\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Import necessary library\n",
                "In this tutorial, we are going to use pytorch, the cutting-edge deep learning framework to complete our task."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 10,
            "metadata": {},
            "outputs": [],
            "source": [
                "import torch\n",
                "import torchvision"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 11,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Python版本信息:\n",
                        "3.8.10 (default, Nov 14 2022, 12:59:47) \n",
                        "[GCC 9.4.0]\n",
                        "torch版本信息:\n",
                        "1.14.0a0+44dac51\n",
                        "python路径:\n",
                        "/usr/bin/python\n"
                    ]
                }
            ],
            "source": [
                "import sys\n",
                "print(\"Python版本信息:\")\n",
                "print(sys.version)\n",
                "\n",
                "import torch\n",
                "print(\"torch版本信息:\")\n",
                "print(torch.__version__)\n",
                "\n",
                "import sys\n",
                "print(\"python路径:\")\n",
                "print(sys.executable)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 12,
            "metadata": {},
            "outputs": [],
            "source": [
                "## Create dataloader, in PyTorch, we feed the trainer data with use of dataloader\n",
                "## We create dataloader with dataset from torchvision, \n",
                "## and we dont have to download it seperately, all automatically done\n",
                "\n",
                "# Define batch size, batch size is how much data you feed for training in one iteration\n",
                "batch_size_train = 64 # We use a small batch size here for training\n",
                "batch_size_test = 1024 #\n",
                "\n",
                "# define how image transformed\n",
                "image_transform = torchvision.transforms.Compose([\n",
                "                               torchvision.transforms.ToTensor(),\n",
                "                               torchvision.transforms.Normalize(\n",
                "                                 (0.1307,), (0.3081,))\n",
                "                             ])\n",
                "#image datasets\n",
                "train_dataset = torchvision.datasets.MNIST('dataset/', \n",
                "                                           train=True, \n",
                "                                           download=True,\n",
                "                                           transform=image_transform)\n",
                "test_dataset = torchvision.datasets.MNIST('dataset/', \n",
                "                                          train=False, \n",
                "                                          download=True,\n",
                "                                          transform=image_transform)\n",
                "#data loaders\n",
                "train_loader = torch.utils.data.DataLoader(train_dataset,\n",
                "                                           batch_size=batch_size_train, \n",
                "                                           shuffle=True)\n",
                "test_loader = torch.utils.data.DataLoader(test_dataset,\n",
                "                                          batch_size=batch_size_test, \n",
                "                                          shuffle=True)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 13,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Label: tensor(8)\n"
                    ]
                },
                {
                    "data": {
                        "image/png": "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\n",
                        "text/plain": [
                            "<Figure size 640x480 with 1 Axes>"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                }
            ],
            "source": [
                "# import library\n",
                "import matplotlib.pyplot as plt\n",
                "# We can check the dataloader\n",
                "_, (example_datas, labels) = next(enumerate(test_loader))\n",
                "sample = example_datas[0][0]\n",
                "# show the data\n",
                "plt.imshow(sample, cmap='gray', interpolation='none')\n",
                "print(\"Label: \"+ str(labels[0]))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 14,
            "metadata": {},
            "outputs": [],
            "source": [
                "## Now we can start to build our CNN model\n",
                "## We first import the pytorch nn module and optimizer\n",
                "import torch.nn as nn\n",
                "import torch.nn.functional as F\n",
                "import torch.optim as optim\n",
                "## Then define the model class\n",
                "class CNN(nn.Module):\n",
                "    def __init__(self):\n",
                "        super(CNN, self).__init__()\n",
                "        #input channel 1, output channel 10\n",
                "        self.conv1 = nn.Conv2d(1, 10, kernel_size=5, stride=1)\n",
                "        #input channel 10, output channel 20\n",
                "        self.conv2 = nn.Conv2d(10, 20, kernel_size=5, stride=1)\n",
                "        #dropout layer\n",
                "        self.conv2_drop = nn.Dropout2d()\n",
                "        #fully connected layer\n",
                "        self.fc1 = nn.Linear(320, 50)\n",
                "        self.fc2 = nn.Linear(50, 10)\n",
                "    def forward(self, x):\n",
                "        x = self.conv1(x)\n",
                "        x = F.max_pool2d(x, 2)\n",
                "        x = F.relu(x)\n",
                "        x = self.conv2(x)\n",
                "        x = self.conv2_drop(x)\n",
                "        x = F.max_pool2d(x, 2)\n",
                "        x = F.relu(x)\n",
                "        x = x.view(-1, 320)\n",
                "        x = self.fc1(x)\n",
                "        x = F.relu(x)\n",
                "        x = F.dropout(x)\n",
                "        x = self.fc2(x)\n",
                "        return F.log_softmax(x, -1)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 15,
            "metadata": {},
            "outputs": [],
            "source": [
                "## create model and optimizer\n",
                "learning_rate = 0.01\n",
                "momentum = 0.5\n",
                "device = \"cpu\"\n",
                "model = CNN().to(device) #using cpu here\n",
                "optimizer = optim.SGD(model.parameters(), lr=learning_rate,\n",
                "                      momentum=momentum)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 16,
            "metadata": {},
            "outputs": [],
            "source": [
                "from tqdm import tqdm_notebook as tqdm\n",
                "##define train function\n",
                "def train(model, device, train_loader, optimizer, epoch, log_interval=10000):\n",
                "    model.train()\n",
                "    for batch_idx, (data, target) in enumerate(train_loader):\n",
                "        data, target = data.to(device), target.to(device)\n",
                "        optimizer.zero_grad()\n",
                "        output = model(data)\n",
                "        loss = F.nll_loss(output, target)\n",
                "        loss.backward()\n",
                "        optimizer.step()\n",
                "        if batch_idx % 100 == 0:\n",
                "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
                "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
                "                100. * batch_idx / len(train_loader), loss.item()))\n",
                "        \n",
                "##define test function\n",
                "def test(model, device, test_loader):\n",
                "    model.eval()\n",
                "    test_loss = 0\n",
                "    correct = 0\n",
                "    with torch.no_grad():\n",
                "        for data, target in test_loader:\n",
                "            data, target = data.to(device), target.to(device)\n",
                "            output = model(data)\n",
                "            test_loss += F.nll_loss(output, target, reduction='sum').item() # sum up batch loss\n",
                "            pred = output.argmax(dim=1, keepdim=True) # get the index of the max log-probability\n",
                "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
                "    test_loss /= len(test_loader.dataset)\n",
                "\n",
                "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
                "        test_loss, correct, len(test_loader.dataset),\n",
                "        100. * correct / len(test_loader.dataset)))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 17,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Start training ...\n",
                        "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.296268\n",
                        "Train Epoch: 1 [6400/60000 (11%)]\tLoss: 1.914678\n",
                        "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 1.078843\n",
                        "Train Epoch: 1 [19200/60000 (32%)]\tLoss: 0.855374\n",
                        "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 0.808118\n",
                        "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 0.708180\n",
                        "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 0.773150\n",
                        "Train Epoch: 1 [44800/60000 (75%)]\tLoss: 0.371319\n",
                        "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 0.490064\n",
                        "Train Epoch: 1 [57600/60000 (96%)]\tLoss: 0.436969\n",
                        "\n",
                        "Test set: Average loss: 0.3583, Accuracy: 8944/10000 (89%)\n",
                        "\n",
                        "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.462343\n",
                        "Train Epoch: 2 [6400/60000 (11%)]\tLoss: 0.460069\n",
                        "Train Epoch: 2 [12800/60000 (21%)]\tLoss: 0.515179\n",
                        "Train Epoch: 2 [19200/60000 (32%)]\tLoss: 0.409296\n",
                        "Train Epoch: 2 [25600/60000 (43%)]\tLoss: 0.656205\n",
                        "Train Epoch: 2 [32000/60000 (53%)]\tLoss: 0.485283\n",
                        "Train Epoch: 2 [38400/60000 (64%)]\tLoss: 0.373111\n",
                        "Train Epoch: 2 [44800/60000 (75%)]\tLoss: 0.328676\n",
                        "Train Epoch: 2 [51200/60000 (85%)]\tLoss: 0.276059\n",
                        "Train Epoch: 2 [57600/60000 (96%)]\tLoss: 0.557857\n",
                        "\n",
                        "Test set: Average loss: 0.2185, Accuracy: 9342/10000 (93%)\n",
                        "\n",
                        "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.328478\n",
                        "Train Epoch: 3 [6400/60000 (11%)]\tLoss: 0.260325\n",
                        "Train Epoch: 3 [12800/60000 (21%)]\tLoss: 0.268295\n",
                        "Train Epoch: 3 [19200/60000 (32%)]\tLoss: 0.538419\n",
                        "Train Epoch: 3 [25600/60000 (43%)]\tLoss: 0.268286\n",
                        "Train Epoch: 3 [32000/60000 (53%)]\tLoss: 0.586474\n",
                        "Train Epoch: 3 [38400/60000 (64%)]\tLoss: 0.185186\n",
                        "Train Epoch: 3 [44800/60000 (75%)]\tLoss: 0.147487\n",
                        "Train Epoch: 3 [51200/60000 (85%)]\tLoss: 0.169221\n",
                        "Train Epoch: 3 [57600/60000 (96%)]\tLoss: 0.291400\n",
                        "\n",
                        "Test set: Average loss: 0.1888, Accuracy: 9477/10000 (95%)\n",
                        "\n",
                        "Done\n"
                    ]
                }
            ],
            "source": [
                "print(\"Start training ...\")\n",
                "num_epoch = 3\n",
                "for epoch in range(1, num_epoch + 1):\n",
                "        train(model, device, train_loader, optimizer, epoch)\n",
                "        test(model, device, test_loader)\n",
                "        \n",
                "print(\"Done\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 18,
            "metadata": {},
            "outputs": [],
            "source": [
                "# from torchsummary import summary\n",
                "# summary(model, (1, 28, 28))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": []
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": []
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3 (ipykernel)",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.10"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}