{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Task\n",
                "Our task is simple, recognize handwritten digits. We will use MNIST dataset for this tutorial.\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Import necessary library\n",
                "In this tutorial, we are going to use pytorch, the cutting-edge deep learning framework to complete our task."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [],
            "source": [
                "import torch\n",
                "import torchvision\n",
                "import sys"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Python版本信息:\n",
                        "3.10.12 (main, Jun 11 2023, 05:26:28) [GCC 11.4.0]\n",
                        "torch版本信息:\n",
                        "2.1.0a0+32f93b1\n",
                        "python路径:\n",
                        "/usr/bin/python\n"
                    ]
                }
            ],
            "source": [
                "print(\"Python版本信息:\")\n",
                "print(sys.version)\n",
                "\n",
                "print(\"torch版本信息:\")\n",
                "print(torch.__version__)\n",
                "\n",
                "print(\"python路径:\")\n",
                "print(sys.executable)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
                        "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to dataset/MNIST/raw/train-images-idx3-ubyte.gz\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "100% 9912422/9912422 [00:00<00:00, 36395789.67it/s]\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Extracting dataset/MNIST/raw/train-images-idx3-ubyte.gz to dataset/MNIST/raw\n",
                        "\n",
                        "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
                        "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to dataset/MNIST/raw/train-labels-idx1-ubyte.gz\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "100% 28881/28881 [00:00<00:00, 1695699.62it/s]"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Extracting dataset/MNIST/raw/train-labels-idx1-ubyte.gz to dataset/MNIST/raw\n",
                        "\n",
                        "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to dataset/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "100% 1648877/1648877 [00:00<00:00, 13468746.21it/s]\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Extracting dataset/MNIST/raw/t10k-images-idx3-ubyte.gz to dataset/MNIST/raw\n",
                        "\n",
                        "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
                        "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to dataset/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "100% 4542/4542 [00:00<00:00, 3050525.02it/s]"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Extracting dataset/MNIST/raw/t10k-labels-idx1-ubyte.gz to dataset/MNIST/raw\n",
                        "\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "\n"
                    ]
                }
            ],
            "source": [
                "## Create dataloader, in PyTorch, we feed the trainer data with use of dataloader\n",
                "## We create dataloader with dataset from torchvision, \n",
                "## and we dont have to download it seperately, all automatically done\n",
                "\n",
                "# Define batch size, batch size is how much data you feed for training in one iteration\n",
                "batch_size_train = 64 # We use a small batch size here for training\n",
                "batch_size_test = 1024 #\n",
                "\n",
                "# define how image transformed\n",
                "image_transform = torchvision.transforms.Compose([\n",
                "                               torchvision.transforms.ToTensor(),\n",
                "                               torchvision.transforms.Normalize(\n",
                "                                 (0.1307,), (0.3081,))\n",
                "                             ])\n",
                "#image datasets\n",
                "train_dataset = torchvision.datasets.MNIST('dataset/', \n",
                "                                           train=True, \n",
                "                                           download=True,\n",
                "                                           transform=image_transform)\n",
                "test_dataset = torchvision.datasets.MNIST('dataset/', \n",
                "                                          train=False, \n",
                "                                          download=True,\n",
                "                                          transform=image_transform)\n",
                "#data loaders\n",
                "train_loader = torch.utils.data.DataLoader(train_dataset,\n",
                "                                           batch_size=batch_size_train, \n",
                "                                           shuffle=True)\n",
                "test_loader = torch.utils.data.DataLoader(test_dataset,\n",
                "                                          batch_size=batch_size_test, \n",
                "                                          shuffle=True)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Label: tensor(8)\n"
                    ]
                },
                {
                    "data": {
                        "image/png": "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",
                        "text/plain": [
                            "<Figure size 640x480 with 1 Axes>"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                }
            ],
            "source": [
                "# import library\n",
                "import matplotlib.pyplot as plt\n",
                "# We can check the dataloader\n",
                "_, (example_datas, labels) = next(enumerate(test_loader))\n",
                "sample = example_datas[0][0]\n",
                "# show the data\n",
                "plt.imshow(sample, cmap='gray', interpolation='none')\n",
                "print(\"Label: \"+ str(labels[0]))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "metadata": {},
            "outputs": [],
            "source": [
                "## Now we can start to build our CNN model\n",
                "## We first import the pytorch nn module and optimizer\n",
                "import torch.nn as nn\n",
                "import torch.nn.functional as F\n",
                "import torch.optim as optim\n",
                "## Then define the model class\n",
                "class CNN(nn.Module):\n",
                "    def __init__(self):\n",
                "        super(CNN, self).__init__()\n",
                "        #input channel 1, output channel 10\n",
                "        self.conv1 = nn.Conv2d(1, 10, kernel_size=5, stride=1)\n",
                "        #input channel 10, output channel 20\n",
                "        self.conv2 = nn.Conv2d(10, 20, kernel_size=5, stride=1)\n",
                "        #dropout layer\n",
                "        self.conv2_drop = nn.Dropout2d()\n",
                "        #fully connected layer\n",
                "        self.fc1 = nn.Linear(320, 50)\n",
                "        self.fc2 = nn.Linear(50, 10)\n",
                "    def forward(self, x):\n",
                "        x = self.conv1(x)\n",
                "        x = F.max_pool2d(x, 2)\n",
                "        x = F.relu(x)\n",
                "        x = self.conv2(x)\n",
                "        x = self.conv2_drop(x)\n",
                "        x = F.max_pool2d(x, 2)\n",
                "        x = F.relu(x)\n",
                "        x = x.view(-1, 320)\n",
                "        x = self.fc1(x)\n",
                "        x = F.relu(x)\n",
                "        x = F.dropout(x)\n",
                "        x = self.fc2(x)\n",
                "        return F.log_softmax(x, -1)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "metadata": {},
            "outputs": [],
            "source": [
                "## create model and optimizer\n",
                "learning_rate = 0.01\n",
                "momentum = 0.5\n",
                "device = \"cpu\"\n",
                "model = CNN().to(device) #using cpu here\n",
                "optimizer = optim.SGD(model.parameters(), lr=learning_rate,\n",
                "                      momentum=momentum)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "metadata": {},
            "outputs": [],
            "source": [
                "from tqdm import tqdm_notebook as tqdm\n",
                "##define train function\n",
                "def train(model, device, train_loader, optimizer, epoch, log_interval=10000):\n",
                "    model.train()\n",
                "    for batch_idx, (data, target) in enumerate(train_loader):\n",
                "        data, target = data.to(device), target.to(device)\n",
                "        optimizer.zero_grad()\n",
                "        output = model(data)\n",
                "        loss = F.nll_loss(output, target)\n",
                "        loss.backward()\n",
                "        optimizer.step()\n",
                "        if batch_idx % 100 == 0:\n",
                "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
                "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
                "                100. * batch_idx / len(train_loader), loss.item()))\n",
                "        \n",
                "##define test function\n",
                "def test(model, device, test_loader):\n",
                "    model.eval()\n",
                "    test_loss = 0\n",
                "    correct = 0\n",
                "    with torch.no_grad():\n",
                "        for data, target in test_loader:\n",
                "            data, target = data.to(device), target.to(device)\n",
                "            output = model(data)\n",
                "            test_loss += F.nll_loss(output, target, reduction='sum').item() # sum up batch loss\n",
                "            pred = output.argmax(dim=1, keepdim=True) # get the index of the max log-probability\n",
                "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
                "    test_loss /= len(test_loader.dataset)\n",
                "\n",
                "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
                "        test_loss, correct, len(test_loader.dataset),\n",
                "        100. * correct / len(test_loader.dataset)))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 8,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Start training ...\n",
                        "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.337725\n",
                        "Train Epoch: 1 [6400/60000 (11%)]\tLoss: 1.955033\n",
                        "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 1.318386\n",
                        "Train Epoch: 1 [19200/60000 (32%)]\tLoss: 0.857806\n",
                        "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 1.036255\n",
                        "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 0.500023\n",
                        "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 0.529630\n",
                        "Train Epoch: 1 [44800/60000 (75%)]\tLoss: 0.590054\n",
                        "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 0.547377\n",
                        "Train Epoch: 1 [57600/60000 (96%)]\tLoss: 0.553042\n",
                        "\n",
                        "Test set: Average loss: 0.3588, Accuracy: 8914/10000 (89%)\n",
                        "\n",
                        "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.352103\n",
                        "Train Epoch: 2 [6400/60000 (11%)]\tLoss: 0.422336\n",
                        "Train Epoch: 2 [12800/60000 (21%)]\tLoss: 0.392431\n",
                        "Train Epoch: 2 [19200/60000 (32%)]\tLoss: 0.381446\n",
                        "Train Epoch: 2 [25600/60000 (43%)]\tLoss: 0.361795\n",
                        "Train Epoch: 2 [32000/60000 (53%)]\tLoss: 0.300085\n",
                        "Train Epoch: 2 [38400/60000 (64%)]\tLoss: 0.275173\n",
                        "Train Epoch: 2 [44800/60000 (75%)]\tLoss: 0.186374\n",
                        "Train Epoch: 2 [51200/60000 (85%)]\tLoss: 0.345736\n",
                        "Train Epoch: 2 [57600/60000 (96%)]\tLoss: 0.312083\n",
                        "\n",
                        "Test set: Average loss: 0.2266, Accuracy: 9343/10000 (93%)\n",
                        "\n",
                        "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.584520\n",
                        "Train Epoch: 3 [6400/60000 (11%)]\tLoss: 0.448360\n",
                        "Train Epoch: 3 [12800/60000 (21%)]\tLoss: 0.434556\n",
                        "Train Epoch: 3 [19200/60000 (32%)]\tLoss: 0.288971\n",
                        "Train Epoch: 3 [25600/60000 (43%)]\tLoss: 0.796921\n",
                        "Train Epoch: 3 [32000/60000 (53%)]\tLoss: 0.475433\n",
                        "Train Epoch: 3 [38400/60000 (64%)]\tLoss: 0.278899\n",
                        "Train Epoch: 3 [44800/60000 (75%)]\tLoss: 0.335121\n",
                        "Train Epoch: 3 [51200/60000 (85%)]\tLoss: 0.259037\n",
                        "Train Epoch: 3 [57600/60000 (96%)]\tLoss: 0.215348\n",
                        "\n",
                        "Test set: Average loss: 0.1843, Accuracy: 9465/10000 (95%)\n",
                        "\n",
                        "Done\n"
                    ]
                }
            ],
            "source": [
                "print(\"Start training ...\")\n",
                "num_epoch = 3\n",
                "for epoch in range(1, num_epoch + 1):\n",
                "        train(model, device, train_loader, optimizer, epoch)\n",
                "        test(model, device, test_loader)\n",
                "        \n",
                "print(\"Done\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 9,
            "metadata": {},
            "outputs": [],
            "source": [
                "# from torchsummary import summary\n",
                "# summary(model, (1, 28, 28))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": []
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": []
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3 (ipykernel)",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.12"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}